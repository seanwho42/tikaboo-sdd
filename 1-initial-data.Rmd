# 1 - initial data reading/setup

## setup
setting up required libraries
```{r}
library(tidyverse)
library(janitor)
library(readxl)
library(ggmap)
library(poppr)
```

## Reading in data
Genotypes contains our microsatellite data, located in 'data-files/AllTikabooValleyGenotypes.csv'. Coords contains our tree coordinates, located in 'data-files/TreeGPS'.

Note: There are some issues that arose when running this analysis with a subset of this data. As such, the following changes were made to the csv:
- TV4284 yb13 Allele #2 changed from 217 to 0 (showing no data)
- Removed TV5188 and TV5087
[TODO: justify/explain/theorize/capitulate on this further?]
[TODO: this was a problem in previous data but don't find it in here: - TV3034 122.5 changed to ?]



```{r}
genotypes <- read_csv('data-files/AllTikabooValleyGenotypes.csv')
dim(genotypes)
head(genotypes)
coords <- read_csv('data-files/TreeGPS.csv')
dim(coords)
```
## Reformatting latitude/longitude
Now we have to do some cleaning of the data. This starts with converting the formatting of the longitude and latitude to decimal format.
```{r}
head(coords)
summary(coords)
```
Looking at our summary data here, it seems that some of our data are missing the first digit of the longitude. We can fix that easily enough.
```{r}
coords = coords %>% mutate(Long = case_when(
  Long < 20 ~ Long + 100,
  .default = Long
))
summary(coords)
```

Alright, now onto other cleaning. For some reason Lat is readying as a character, so we need to fix that.
```{r}
coords <- coords %>% mutate(Lat = as.numeric(Lat))
```

Now we have to convert the format to decimals instead of using minutes
```{r}
coords <- coords %>%
  mutate(Y = (Lat + `Lat '`/60), X = -(Long + `Long '`/60)) %>%
  unique()
head(coords$Y)
head(coords$X)
```
## Removing duplicated rows
And now cleaning up the genotype data. There are some duplicated rows which need to be removed.
```{r}
head(genotypes)
summary(genotypes)

# were some duplicates of rows so this gets rid of them
dim(genotypes)
genotypes <- genotypes %>% unique()
dim(genotypes)
```

[TODO: add more data/ initial exploration to characterize the data?]

## Filtering decimals from microsatellite data
Now we have to remove any non-integer data from the genotypes. We'll do this with a for loop.
```{r}
dim(genotypes)
for (col in colnames(genotypes)) {
  unfiltered_len = length(genotypes[[col]])
  if (col != 'Tree') {
    genotypes = filter(genotypes, (genotypes[[col]] %% 1 == 0))
  }
  num_removed = unfiltered_len - length(genotypes[[col]])
  if (num_removed > 0){
    print(paste(toString(num_removed), 'filtered from', col, sep=' '))
  }
}
dim(genotypes)
```
Now we've removed 9 entries from our genotypes data.

## Dealing with duplicated conflicting data
Let's try to join our data
```{r}
geno_coords <- inner_join(genotypes, coords, by = c("Tree" = "Tree"))
dim(geno_coords)
```

It looks like we're having multiple matches when joining. Let's take another look at the genotypes and coordinate data.
```{r}
length(genotypes$Tree)

length(genotypes$Tree %>% unique())
```

This confirms there are some duplicates of tree ids here. We can find these simply enough.
```{r}
duplicated_genotypes_trees = genotypes %>% filter(duplicated(Tree)) %>% select(Tree)

duplicated_genotypes_trees
```


Let's cut these trees out from our dataset.
```{r}
genotypes <- genotypes %>% filter(!(Tree %in% duplicated_genotypes_trees$Tree))
dim(genotypes)
```

Now, let's check the coordinates for duplicates.
```{r}
length(coords$Tree)

length(coords$Tree %>% unique())
```

It looks like we have some here, as well. We can use the same code to figure out these IDs.

```{r}
duplicated_coords_trees <- coords %>% filter(duplicated(Tree)) %>% select(Tree)
duplicated_coords_trees
```
Let's see how much the coordinate data differs across these duplicates, to see if they're worth keeping or if we can't trust the duplicated data at all.
```{r}
coords %>%
  filter((Tree %in% duplicated_coords_trees$Tree)) %>% 
  group_by(Tree)
```

Manually calculating the differences in distances across duplicates, the worst we see here at a cursory glance is .2 miles different across the two recordings of TV7037. Some are only a matter of feet different, but it's better to just cut all these out entirely, especially considering this only accounts for 9 samples. 

```{r}
coords <- coords %>% filter(!(Tree %in% duplicated_coords_trees$Tree))
dim(coords)
```
This looking great.. however, we can see that some trees are missing data here.
```{r}
genotypes %>% arrange(genotypes %>% select(-Tree))
```
Let's remove these from our dataset. There's probably a better way to do conditional filtering but this is ther first thing I thought of that didn't require listing all of the columns.
```{r}
# grouping by tree to find maximum values, and then filtering to find all the trees where that is only 0, meaning they have no genetic data
missing_genotypes <- genotypes %>% 
  gather(locus, value, -Tree) %>%
  group_by(Tree) %>% 
  summarize(max = max(value)) %>% 
  filter(max == 0) %>%
  select(-max)
missing_genotypes
```
Now that we've found the trees with missing data, let's cut them

```{r}
# filtering out those with ids in the tibble of those missing genotypes

genotypes <- genotypes %>% filter(!(Tree %in% missing_genotypes$Tree))
dim(genotypes)
```

Now we've got to do some population genetic analysis to weed out potential clones. We can git rid of some clones by checking for completely identical genotypes, but some are missing data, and we want to do a bit more in-depth analysis. We're going to do this with the R package poppr, but to do this we have to create a new CSV file and format it for the package to read it properly.
```{r}
# checking to see how many unique genotypes
genotypes %>% select(-Tree) %>% unique()

write_csv(genotypes, 'poppr_genotypes.csv')
```


Now we have to add formatting per instructions on this page https://grunwaldlab.github.io/Population_Genetics_in_R/Data_Preparation.html. The complete file is in ```'data-files/poppr_genotypes.csv'```

```{r}
poppr_genotypes = read.genalex('data-files/poppr_genotypes.csv')
```





Now we redefine the geno_coords data.
```{r}
geno_coords <- inner_join(genotypes, coords, by = c("Tree" = "Tree"))
dim(geno_coords)
head(geno_coords)
```
It looks like there were 11 samples which had missing/filtered out coordinate data. Now we have coordinates and microsatellite data ready for further analysis.

NOTE: in order for the ggmaps functions below to function, you will need to register an API key in the R console using ```register_google("API_KEY")```.
This sort of key is a static map key [TODO: hyperlink to the google api page], which has free unlimited usages. Still, best security practices dictate not sharing API keys.
```{r}
# [TODO: delete this key when uploading to github AIzaSyCOTXxcPzKTjJCub58MglbKZxeHvSAKFvY]

```
Now, let's make some maps to visualize our data. This will be accomplished using ggmaps. First, we have to set our boundary box for the map.
```{r}
map_lon_center = (max(geno_coords$X)+min(geno_coords$X))/2
map_lat_center = (max(geno_coords$Y)+min(geno_coords$Y))/2

# map_lat_center = 37.53


```

Then we build the map itself
```{r}
map_area <- get_googlemap(center = c(lon = map_lon_center, lat = map_lat_center),
 zoom = 12,
 maptype = 'terrain')

ggmap(map_area) +
  # geom_point(geno_coords, mapping=aes(X, Y), size = 0.5) +
  geom_point(geno_coords,
               mapping=aes(x=X, y=Y),
               size=.5)
```


Let's also try and do some grouping to understand our clusters of data here. We can do this based off of the prefixes in our dataset, and use regex to parse those from the id strings.
```{r}
grouped_geno_coords = geno_coords %>% mutate(id_group = as.factor(gsub('(\\d*)\\w?$', '', Tree)))

grouped_geno_coords %>% ggplot()+
  geom_point(aes(X, Y, color=id_group))

ggmap(map_area) +
  # geom_point(geno_coords, mapping=aes(X, Y), size = 0.5) +
  geom_point(grouped_geno_coords,
             mapping=aes(x=X, y=Y, color=id_group),
             size=1)
```



